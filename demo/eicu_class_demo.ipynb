{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0902 17:01:42.031465 140275218188096 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/daniel/.virtualenvs/tf/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
      "W0902 17:01:42.043801 140275218188096 deprecation_wrapper.py:119] From /home/daniel/.virtualenvs/tf/lib/python3.6/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "from neoglia.workers.connect_workers import connect\n",
    "from neoglia.learn.utils import setup_logging\n",
    "from neoglia.learn.config import LearnConfig\n",
    "from neoglia.learn.losses import cross_entropy, binary_cross_entropy\n",
    "from neoglia.learn.models import ConvNet, FFNet\n",
    "from neoglia.learn.learner import Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create STDERR handler\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to data nodes\n",
    "\n",
    "In this demo, we have 3 distinct hospitals. Each is an indenpendent EC2 instance on AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neoglia.workers.connect_workers - INFO - Connected to worker h1.\n",
      "neoglia.workers.connect_workers - INFO - Connected to worker h2.\n",
      "neoglia.workers.connect_workers - INFO - Connected to worker h3.\n"
     ]
    }
   ],
   "source": [
    "h1, h2, h3 = connect(local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the datasets they have and the dimensions of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mnist_train',\n",
       " 'mnist_test',\n",
       " 'eicu_class_train',\n",
       " 'eicu_class_test',\n",
       " 'eicu_reg_train',\n",
       " 'eicu_reg_test']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mnist_train': (None, 28, 28),\n",
       " 'mnist_test': (None, 28, 28),\n",
       " 'eicu_class_train': (None, 103),\n",
       " 'eicu_class_test': (None, 103),\n",
       " 'eicu_reg_train': (None, 103),\n",
       " 'eicu_reg_test': (None, 103)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.dataset_input_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mnist_train': (None, 10),\n",
       " 'mnist_test': (None, 10),\n",
       " 'eicu_class_train': (None, 1),\n",
       " 'eicu_class_test': (None, 1),\n",
       " 'eicu_reg_train': (None, 1),\n",
       " 'eicu_reg_test': (None, 1)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.dataset_output_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mnist_train': 24754,\n",
       " 'mnist_test': 10000,\n",
       " 'eicu_class_train': 4778,\n",
       " 'eicu_class_test': 5421,\n",
       " 'eicu_reg_train': 4778,\n",
       " 'eicu_reg_test': 5421}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mnist_train': 17181,\n",
       " 'mnist_test': 10000,\n",
       " 'eicu_class_train': 3981,\n",
       " 'eicu_class_test': 5421,\n",
       " 'eicu_reg_train': 3981,\n",
       " 'eicu_reg_test': 5421}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2.dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a convolutional neural network on the mnist dataset with federated averaging\n",
    "\n",
    "Each hospital holds a subset of the training data but they all share the same test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the config file for this experiment\n",
    "\n",
    "This holds everything from the learning rate to the batch size. \n",
    "\n",
    "First let's check the available parameters. Note, this object can take a yml config file (good for reproducible experiments) or be parametrised when instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mLearnConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m[\u001b[0m\u001b[0;34m'config_file=None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_dataset_name=None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_dataset_name=None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_batch_size=64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_batch_size=128'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_epochs=40'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fed_after_n_batches=10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr=0.1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda=False'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seed=42'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'save_model=True'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'verbose=True'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Config dict object, holding all parameters for the training and evaluation.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Constructor of the subclassed dict object.\n",
       "\n",
       "Args:\n",
       "    config_file (str): Location of config YAML file. If provided, all\n",
       "        parameters that are defined within will override the defaults here.\n",
       "    train_dataset_name (str): Name of the remote dataset to train on.\n",
       "    test_dataset_name (str): Name of the remote dataset to test on.\n",
       "    train_batch_size (int): Batch size for training.\n",
       "    test_batch_size (int): Batch size for evaluation.\n",
       "    train_epochs (int): Number of epochs performed altogether for training on\n",
       "        remote workers.\n",
       "    fed_after_n_batches (int): Number of training epochs performed on each\n",
       "        remote worker before averaging global model.\n",
       "    lr (float): Learning rate for the optimizer.\n",
       "    cuda (bool): Whether the remote workers have GPUs and CUDA enabled.\n",
       "    seed (int): Seed for reproducibility.\n",
       "    save_model (bool): Whether to save the global model. If yes, it is\n",
       "        saved where the python interpreter is running.\n",
       "    verbose (bool): Verbosity - false: not entirely silent, but quite minimal.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Dropbox/NG/proto/proto/src/neoglia/learn/config.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?LearnConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config_file': 'eicu_class_config.yml',\n",
       " 'train_dataset_name': 'eicu_class_train',\n",
       " 'test_dataset_name': 'eicu_class_test',\n",
       " 'train_batch_size': 64,\n",
       " 'test_batch_size': 128,\n",
       " 'train_epochs': 40,\n",
       " 'fed_after_n_batches': 5,\n",
       " 'lr': 0.1,\n",
       " 'cuda': False,\n",
       " 'seed': 42,\n",
       " 'save_model': True,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = LearnConfig(\"eicu_class_config.yml\")\n",
    "config.fed_after_n_batches = 5\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model architecture and loss function\n",
    "\n",
    "Define a model architecture in Torch, or simply load one of NeoGlia's predefined ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNet(\n",
       "  (fc1): Linear(in_features=103, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (do): Dropout(p=0.25)\n",
       "  (sigm): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FFNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use cross entropy in this example as a loss function as this is a multi-class problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training and evaluating the model in a federated manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_learner = Learner(\n",
    "    config,\n",
    "    model, \n",
    "    binary_cross_entropy, \n",
    "    (h1, h2, h3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neoglia.learn.learner - INFO - Starting epoch 1/41\n",
      "neoglia.learn.learner - INFO - Training round: 0, worker: h2, avg_loss: tensor(0.6199, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 0, worker: h3, avg_loss: tensor(0.5570, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 0, worker: h1, avg_loss: tensor(0.5653, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Starting epoch 2/41\n",
      "neoglia.learn.learner - INFO - Training round: 1, worker: h3, avg_loss: tensor(0.4900, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 1, worker: h2, avg_loss: tensor(0.3912, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 1, worker: h1, avg_loss: tensor(0.4898, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Starting epoch 3/41\n",
      "neoglia.learn.learner - INFO - Training round: 2, worker: h2, avg_loss: tensor(0.3726, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 2, worker: h1, avg_loss: tensor(0.8640, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 2, worker: h3, avg_loss: tensor(0.4449, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Starting epoch 4/41\n",
      "neoglia.learn.learner - INFO - Training round: 3, worker: h1, avg_loss: tensor(0.3915, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 3, worker: h2, avg_loss: tensor(0.4024, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 3, worker: h3, avg_loss: tensor(0.3370, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Starting epoch 5/41\n",
      "neoglia.learn.learner - INFO - Training round: 4, worker: h3, avg_loss: tensor(0.3705, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 4, worker: h1, avg_loss: tensor(0.4754, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 4, worker: h2, avg_loss: tensor(0.3860, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Starting epoch 6/41\n",
      "neoglia.learn.learner - INFO - Training round: 5, worker: h1, avg_loss: tensor(0.4143, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 5, worker: h2, avg_loss: tensor(0.3684, grad_fn=<MeanBackward1>)\n",
      "neoglia.learn.learner - INFO - Training round: 5, worker: h3, avg_loss: tensor(0.3122, grad_fn=<MeanBackward1>)\n",
      "syft.workers.websocket_client - WARNING - Websocket connection closed (worker: h1)\n",
      "syft.workers.websocket_client - WARNING - Created new websocket connection\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Websocket connection closed and creation of new connection failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f28fe2528163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfed_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/NG/proto/proto/src/neoglia/learn/learner.py\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;34masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_train_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event loop stopped before Future completed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/asyncio/tasks.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/NG/proto/proto/src/neoglia/learn/learner.py\u001b[0m in \u001b[0;36m_train_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0mmodel_identifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0mworker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworker_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                     )\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/NG/proto/proto/src/neoglia/learn/learner.py\u001b[0m in \u001b[0;36m_evaluate_model_on_worker\u001b[0;34m(self, model_identifier, worker, model)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mdataset_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mreturn_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mreturn_raw_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         )\n\u001b[1;32m    204\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf/lib/python3.6/site-packages/syft/workers/websocket_client.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset_key, return_histograms, nr_bins, return_loss, return_raw_accuracy)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mnr_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnr_bins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mreturn_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mreturn_raw_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_raw_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf/lib/python3.6/site-packages/syft/workers/websocket_client.py\u001b[0m in \u001b[0;36m_send_msg_and_deserialize\u001b[0;34m(self, command_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Send the message and return the deserialized response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mserialized_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf/lib/python3.6/site-packages/syft/workers/websocket_client.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 raise RuntimeError(\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0;34m\"Websocket connection closed and creation of new connection failed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 )\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Websocket connection closed and creation of new connection failed."
     ]
    }
   ],
   "source": [
    "fed_learner.train_eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
