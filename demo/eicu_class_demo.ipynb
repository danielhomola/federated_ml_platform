{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf_encrypted:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/danielhomola/.virtualenvs/ng/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/danielhomola/.virtualenvs/ng/lib/python3.6/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/danielhomola/.virtualenvs/ng/lib/python3.6/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "from neoglia.workers.connect_workers import connect\n",
    "from neoglia.learn.utils import setup_logging\n",
    "from neoglia.learn.config import LearnConfig\n",
    "from neoglia.learn.losses import binary_cross_entropy\n",
    "from neoglia.learn.models import FFNet\n",
    "from neoglia.learn.learner import Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create STDERR handler\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to data nodes\n",
    "\n",
    "In this demo, we have 3 distinct hospitals. Each is an indenpendent EC2 instance on AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neoglia.workers.connect_workers - INFO - Connected to worker h1.\n",
      "neoglia.workers.connect_workers - INFO - Connected to worker h2.\n",
      "neoglia.workers.connect_workers - INFO - Connected to worker h3.\n"
     ]
    }
   ],
   "source": [
    "h1, h2, h3 = connect(local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the datasets they have and the dimensions of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - -mnist_train:\n",
      "\tdata size: [24754, 28, 28],\n",
      "\ttarget size: [24754]\n",
      "-mnist_test:\n",
      "\tdata size: [10000, 28, 28],\n",
      "\ttarget size: [10000]\n",
      "-eicu_class_train:\n",
      "\tdata size: [4778, 103],\n",
      "\ttarget size: [4778]\n",
      "-eicu_class_test:\n",
      "\tdata size: [5421, 103],\n",
      "\ttarget size: [5421]\n",
      "-eicu_reg_train:\n",
      "\tdata size: [4778, 103],\n",
      "\ttarget size: [4778]\n",
      "-eicu_reg_test:\n",
      "\tdata size: [5421, 103],\n",
      "\ttarget size: [5421]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(h1.list_datasets())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a convolutional neural network on the mnist dataset with federated averaging\n",
    "\n",
    "Each hospital holds a subset of the training data but they all share the same test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the config file for this experiment\n",
    "\n",
    "This holds everything from the learning rate to the batch size. \n",
    "\n",
    "First let's check the available parameters. Note, this object can take a yml config file (good for reproducible experiments) or be parametrised when instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mLearnConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconfig_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_dataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtest_dataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtest_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfed_after_n_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SGD'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moptimizer_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Config dict object, holding all parameters for the training and evaluation.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Constructor of the subclassed dict object.\n",
       "\n",
       "Args:\n",
       "    config_file (str): Location of config YAML file. If provided, all\n",
       "        parameters that are defined within will override the defaults here.\n",
       "    train_dataset_name (str): Name of the remote dataset to train on.\n",
       "    test_dataset_name (str): Name of the remote dataset to test on.\n",
       "    train_batch_size (int): Batch size for training.\n",
       "    test_batch_size (int): Batch size for evaluation.\n",
       "    train_epochs (int): Number of epochs performed altogether for training on\n",
       "        remote workers.\n",
       "    fed_after_n_batches (int): Number of training epochs performed on each\n",
       "        remote worker before averaging global model.\n",
       "    metrics (tuple<str>): Metrics to use for evaluation of the model. Use any\n",
       "        of: accuracy, precision, recall, mse, mae.\n",
       "    optimizer (str): Name of an optimizer in torch.optim module.\n",
       "    optimizer_params (dict): Dict of params for the optimizer.\n",
       "    cuda (bool): Whether the remote workers have GPUs and CUDA enabled.\n",
       "    seed (int): Seed for reproducibility.\n",
       "    save_model (bool): Whether to save the global model. If yes, it is\n",
       "        saved where the python interpreter is running.\n",
       "    verbose (bool): Verbosity - false: not entirely silent, but quite minimal.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Dropbox/NG/proto/proto/src/neoglia/learn/config.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?LearnConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config_file': 'eicu_class_config.yml',\n",
       " 'train_dataset_name': 'eicu_class_train',\n",
       " 'test_dataset_name': 'eicu_class_test',\n",
       " 'train_batch_size': 512,\n",
       " 'test_batch_size': 1024,\n",
       " 'train_epochs': 10,\n",
       " 'fed_after_n_batches': 2,\n",
       " 'metrics': ['precision', 'recall'],\n",
       " 'optimizer': 'SGD',\n",
       " 'optimizer_params': {'lr': 0.05, 'momentum': 0.9},\n",
       " 'cuda': False,\n",
       " 'seed': 42,\n",
       " 'save_model': True,\n",
       " 'verbose': True,\n",
       " 'regression': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = LearnConfig(config_file=\"eicu_class_config.yml\")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model architecture and loss function\n",
    "\n",
    "Define a model architecture in Torch, or simply load one of NeoGlia's predefined ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFNet(\n",
    "    input_d=103, \n",
    "    dense_size=1024,\n",
    "    dropout_rate=0.5,\n",
    "    final='sigmoid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;32mclass\u001b[0m \u001b[0mFFNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Feed-forward network with dropout on tabular, numeric data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns probabilities after sigmoid and not logits.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Constructor of neural net.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            input_d (int): Input dimensions to the first layers, i.e. num cols in data.\u001b[0m\n",
       "\u001b[0;34m            dense_size (int): Size of the first layer. There are 3 layers in this\u001b[0m\n",
       "\u001b[0;34m                architecture, the 2nd has dense_size/2 the 3rd has dense_size/4 units.\u001b[0m\n",
       "\u001b[0;34m            dropout_rate (float): Rate of dropout applied to each fully connected layers.\u001b[0m\n",
       "\u001b[0;34m            final (str): What should the final activation layer be. Options are:\u001b[0m\n",
       "\u001b[0;34m                sigmoid, relu, None.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFFNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parameter final should be either None, sigmoid or relu.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%psource FFNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use cross entropy in this example as a loss function as this is a multi-class problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training and evaluating the model in a federated manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_learner = Learner(\n",
    "    config=config,\n",
    "    model=model, \n",
    "    model_input_dim=[1, 103],\n",
    "    loss_fn=binary_cross_entropy, \n",
    "    workers=(h1, h2, h3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neoglia.learn.learner - INFO - Starting epoch 1/10\n",
      "neoglia.learn.learner - INFO - Training round: 1, worker: h2, avg_loss: 0.6427\n",
      "neoglia.learn.learner - INFO - Training round: 1, worker: h3, avg_loss: 0.6848\n",
      "neoglia.learn.learner - INFO - Training round: 1, worker: h1, avg_loss: 0.6288\n",
      "neoglia.learn.learner - INFO - Starting epoch 2/10\n",
      "neoglia.learn.learner - INFO - Training round: 2, worker: h1, avg_loss: 0.6934\n",
      "neoglia.learn.learner - INFO - Training round: 2, worker: h3, avg_loss: 0.6241\n",
      "neoglia.learn.learner - INFO - Training round: 2, worker: h2, avg_loss: 0.6167\n",
      "neoglia.learn.learner - INFO - h1: Test set: Average loss: 0.0007\n",
      "neoglia.learn.learner - INFO - \t- precision: 0.0000\n",
      "neoglia.learn.learner - INFO - \t- recall: 0.0000\n",
      "neoglia.learn.learner - INFO - h2: Test set: Average loss: 0.0007\n",
      "neoglia.learn.learner - INFO - \t- precision: 0.0000\n",
      "neoglia.learn.learner - INFO - \t- recall: 0.0000\n",
      "neoglia.learn.learner - INFO - h3: Test set: Average loss: 0.0007\n",
      "neoglia.learn.learner - INFO - \t- precision: 0.0000\n",
      "neoglia.learn.learner - INFO - \t- recall: 0.0000\n",
      "neoglia.learn.learner - INFO - Federated model: Test set: Average loss: 0.0007\n",
      "neoglia.learn.learner - INFO - \t- precision: 0.0000\n",
      "neoglia.learn.learner - INFO - \t- recall: 0.0000\n",
      "neoglia.learn.learner - INFO - Starting epoch 3/10\n",
      "neoglia.learn.learner - INFO - Training round: 3, worker: h3, avg_loss: 0.5983\n",
      "neoglia.learn.learner - INFO - Training round: 3, worker: h2, avg_loss: 0.5894\n",
      "neoglia.learn.learner - INFO - Training round: 3, worker: h1, avg_loss: 0.5436\n",
      "neoglia.learn.learner - INFO - Starting epoch 4/10\n",
      "neoglia.learn.learner - INFO - Training round: 4, worker: h1, avg_loss: 0.5622\n",
      "neoglia.learn.learner - INFO - Training round: 4, worker: h2, avg_loss: 0.5149\n",
      "neoglia.learn.learner - INFO - Training round: 4, worker: h3, avg_loss: 0.5708\n",
      "neoglia.learn.learner - INFO - h1: Test set: Average loss: 0.0006\n",
      "neoglia.learn.learner - INFO - \t- precision: 0.0000\n",
      "neoglia.learn.learner - INFO - \t- recall: 0.0000\n",
      "neoglia.learn.learner - INFO - h2: Test set: Average loss: 0.0006\n",
      "neoglia.learn.learner - INFO - \t- precision: 0.0000\n",
      "neoglia.learn.learner - INFO - \t- recall: 0.0000\n",
      "neoglia.learn.learner - INFO - h3: Test set: Average loss: 0.0007\n",
      "neoglia.learn.learner - INFO - \t- precision: 0.0000\n",
      "neoglia.learn.learner - INFO - \t- recall: 0.0000\n",
      "neoglia.learn.learner - INFO - Federated model: Test set: Average loss: 0.0006\n",
      "neoglia.learn.learner - INFO - \t- precision: 0.0000\n",
      "neoglia.learn.learner - INFO - \t- recall: 0.0000\n",
      "neoglia.learn.learner - INFO - Starting epoch 5/10\n",
      "neoglia.learn.learner - INFO - Training round: 5, worker: h3, avg_loss: 0.5613\n"
     ]
    }
   ],
   "source": [
    "fed_learner.train_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for worker in (h1, h2, h3):\n",
    "    worker.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
