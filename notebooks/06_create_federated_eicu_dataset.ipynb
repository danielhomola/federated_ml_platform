{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook, takes the one row per patient data we used in previous notebooks from the top5 hospitals from the eICU dataset and prepares it so it can be used on a remote worker. \n",
    "\n",
    "We only use the apache and lab result vars which are continuous. The first 3 hospitals are used for training, whereas the 4th and 5th are merged for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "establish connection to DB and define helper function for running queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from proto.etl.config import SSHInfoEicu, DBInfoEicu\n",
    "from proto.etl.utils import connect_to_db_via_ssh, run_eicu_query, get_column_completeness, load_schema_for_modelling\n",
    "\n",
    "conn = connect_to_db_via_ssh(SSHInfoEicu, DBInfoEicu)\n",
    "cursor = conn.cursor()\n",
    "query_schema = 'set search_path to eicu_crd;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add hospital id to the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the hospital id for the patients in the top5 hospitals\n",
    "query = \"\"\"\n",
    "    select m.patientunitstayid, hospitalid\n",
    "    from patient_top5hospitals_mort_dataset as m\n",
    "    join\n",
    "        (\n",
    "        select hospitalid, patientunitstayid\n",
    "        from patient\n",
    "        ) as p\n",
    "    on\n",
    "        p.patientunitstayid=m.patientunitstayid\n",
    "\"\"\"\n",
    "\n",
    "df_hospitals = run_eicu_query(query, conn)\n",
    "df_hospitals.set_index('patientunitstayid', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalid</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>7059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167</td>\n",
       "      <td>6092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264</td>\n",
       "      <td>5237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420</td>\n",
       "      <td>4679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176</td>\n",
       "      <td>4328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hospitalid     n\n",
       "0          73  7059\n",
       "1         167  6092\n",
       "2         264  5237\n",
       "3         420  4679\n",
       "4         176  4328"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out the top5's size and hospitalid\n",
    "query = \"\"\"\n",
    "    select hospitalid, count(patientunitstayid) as n\n",
    "    from patient \n",
    "    group by hospitalid \n",
    "    order by n desc\n",
    "\"\"\"\n",
    "\n",
    "df_hospitals = run_eicu_query(query, conn)\n",
    "df_hospitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data, add hospital id\n",
    "df = pd.read_csv('orpp_all.csv', index_col=0)\n",
    "df = df.join(df_hospitals)\n",
    "\n",
    "# recode hospital ids - largest 3 we keep separate, 4th and 5th become test \n",
    "df.hospitalid[df.hospitalid==73] = 1\n",
    "df.hospitalid[df.hospitalid==167] = 2\n",
    "df.hospitalid[df.hospitalid==264] = 3\n",
    "df.hospitalid[df.hospitalid==420] = 4\n",
    "df.hospitalid[df.hospitalid==176] = 4\n",
    "\n",
    "# only keep numeric cols and hospitalid\n",
    "cols_to_keep = df.columns[list(range(4,107)) + [-1]]\n",
    "df = df[cols_to_keep]\n",
    "\n",
    "# save the X matrix\n",
    "df.to_csv('../src/proto/workers/x.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the y outcome csv\n",
    "df_y = pd.read_csv('mort_y.csv', index_col=0)\n",
    "\n",
    "# make sure we have the patients in the same order\n",
    "sum(df_y.index.values == df.index.values) == df.shape[0]\n",
    "\n",
    "df_y.to_csv('../src/proto/workers/y.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define PyTorch dataset from eICU dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EicuDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads the data of 16k patients from the eICU dataset and the \n",
    "    corresponding labels for mortality prediction and length of stay\n",
    "    prediction. \n",
    "    \n",
    "    We only use the apache and lab result features which are continuous.\n",
    "    Each patient is represented as a single row, with their data from \n",
    "    the first 24 hours.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, hospital, outcome='hosp_mort'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with data files.\n",
    "            hospital (int): Which hospitals data to keep\n",
    "                1-3 are training, 4 is testing\n",
    "            outcome (string): 'hosp_mort' or 'icu_los_hours'\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        # load and scale x, and restrict to requested hospital data\n",
    "        self.df_x = pd.read_csv(os.path.join(self.root_dir, 'x.csv'))\n",
    "        to_keep = self.df_x.hospitalid.values == hospital\n",
    "        self.df_x.drop('hospitalid', axis=1, inplace=True)\n",
    "        self.df_x = self.df_x[to_keep]\n",
    "        scaler = RobustScaler(quantile_range=(10.0, 90.0))\n",
    "        self.x = scaler.fit_transform(self.df_x.values)\n",
    "        \n",
    "        # load and select outcome\n",
    "        self.y = pd.read_csv(\n",
    "            os.path.join(self.root_dir, 'y.csv')\n",
    "        )[outcome].values\n",
    "        \n",
    "                      \n",
    "    def __len__(self):\n",
    "        return len(self.df_x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.x[idx,:], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eicu_data = EicuDataset('../src/proto/workers/', 1)\n",
    "dataloader = DataLoader(eicu_data, batch_size=50, shuffle=True, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([50, 103]) torch.Size([50])\n",
      "1 torch.Size([50, 103]) torch.Size([50])\n",
      "2 torch.Size([50, 103]) torch.Size([50])\n",
      "3 torch.Size([50, 103]) torch.Size([50])\n",
      "4 torch.Size([50, 103]) torch.Size([50])\n",
      "5 torch.Size([50, 103]) torch.Size([50])\n",
      "6 torch.Size([50, 103]) torch.Size([50])\n",
      "7 torch.Size([50, 103]) torch.Size([50])\n",
      "8 torch.Size([50, 103]) torch.Size([50])\n",
      "9 torch.Size([50, 103]) torch.Size([50])\n",
      "10 torch.Size([50, 103]) torch.Size([50])\n",
      "11 torch.Size([50, 103]) torch.Size([50])\n",
      "12 torch.Size([50, 103]) torch.Size([50])\n",
      "13 torch.Size([50, 103]) torch.Size([50])\n",
      "14 torch.Size([50, 103]) torch.Size([50])\n",
      "15 torch.Size([50, 103]) torch.Size([50])\n",
      "16 torch.Size([50, 103]) torch.Size([50])\n",
      "17 torch.Size([50, 103]) torch.Size([50])\n",
      "18 torch.Size([50, 103]) torch.Size([50])\n",
      "19 torch.Size([50, 103]) torch.Size([50])\n",
      "20 torch.Size([50, 103]) torch.Size([50])\n",
      "21 torch.Size([50, 103]) torch.Size([50])\n",
      "22 torch.Size([50, 103]) torch.Size([50])\n",
      "23 torch.Size([50, 103]) torch.Size([50])\n",
      "24 torch.Size([50, 103]) torch.Size([50])\n",
      "25 torch.Size([50, 103]) torch.Size([50])\n",
      "26 torch.Size([50, 103]) torch.Size([50])\n",
      "27 torch.Size([50, 103]) torch.Size([50])\n",
      "28 torch.Size([50, 103]) torch.Size([50])\n",
      "29 torch.Size([50, 103]) torch.Size([50])\n",
      "30 torch.Size([50, 103]) torch.Size([50])\n",
      "31 torch.Size([50, 103]) torch.Size([50])\n",
      "32 torch.Size([50, 103]) torch.Size([50])\n",
      "33 torch.Size([50, 103]) torch.Size([50])\n",
      "34 torch.Size([50, 103]) torch.Size([50])\n",
      "35 torch.Size([50, 103]) torch.Size([50])\n",
      "36 torch.Size([50, 103]) torch.Size([50])\n",
      "37 torch.Size([50, 103]) torch.Size([50])\n",
      "38 torch.Size([50, 103]) torch.Size([50])\n",
      "39 torch.Size([50, 103]) torch.Size([50])\n",
      "40 torch.Size([50, 103]) torch.Size([50])\n",
      "41 torch.Size([50, 103]) torch.Size([50])\n",
      "42 torch.Size([50, 103]) torch.Size([50])\n",
      "43 torch.Size([50, 103]) torch.Size([50])\n",
      "44 torch.Size([50, 103]) torch.Size([50])\n",
      "45 torch.Size([50, 103]) torch.Size([50])\n",
      "46 torch.Size([50, 103]) torch.Size([50])\n",
      "47 torch.Size([50, 103]) torch.Size([50])\n",
      "48 torch.Size([50, 103]) torch.Size([50])\n",
      "49 torch.Size([50, 103]) torch.Size([50])\n",
      "50 torch.Size([50, 103]) torch.Size([50])\n",
      "51 torch.Size([50, 103]) torch.Size([50])\n",
      "52 torch.Size([50, 103]) torch.Size([50])\n",
      "53 torch.Size([50, 103]) torch.Size([50])\n",
      "54 torch.Size([50, 103]) torch.Size([50])\n",
      "55 torch.Size([50, 103]) torch.Size([50])\n",
      "56 torch.Size([50, 103]) torch.Size([50])\n",
      "57 torch.Size([50, 103]) torch.Size([50])\n",
      "58 torch.Size([50, 103]) torch.Size([50])\n",
      "59 torch.Size([50, 103]) torch.Size([50])\n",
      "60 torch.Size([50, 103]) torch.Size([50])\n",
      "61 torch.Size([50, 103]) torch.Size([50])\n",
      "62 torch.Size([50, 103]) torch.Size([50])\n",
      "63 torch.Size([50, 103]) torch.Size([50])\n",
      "64 torch.Size([50, 103]) torch.Size([50])\n",
      "65 torch.Size([50, 103]) torch.Size([50])\n",
      "66 torch.Size([50, 103]) torch.Size([50])\n",
      "67 torch.Size([50, 103]) torch.Size([50])\n",
      "68 torch.Size([50, 103]) torch.Size([50])\n",
      "69 torch.Size([50, 103]) torch.Size([50])\n",
      "70 torch.Size([50, 103]) torch.Size([50])\n",
      "71 torch.Size([50, 103]) torch.Size([50])\n",
      "72 torch.Size([50, 103]) torch.Size([50])\n",
      "73 torch.Size([50, 103]) torch.Size([50])\n",
      "74 torch.Size([50, 103]) torch.Size([50])\n",
      "75 torch.Size([50, 103]) torch.Size([50])\n",
      "76 torch.Size([50, 103]) torch.Size([50])\n",
      "77 torch.Size([50, 103]) torch.Size([50])\n",
      "78 torch.Size([50, 103]) torch.Size([50])\n",
      "79 torch.Size([50, 103]) torch.Size([50])\n",
      "80 torch.Size([50, 103]) torch.Size([50])\n",
      "81 torch.Size([50, 103]) torch.Size([50])\n",
      "82 torch.Size([50, 103]) torch.Size([50])\n",
      "83 torch.Size([50, 103]) torch.Size([50])\n",
      "84 torch.Size([50, 103]) torch.Size([50])\n",
      "85 torch.Size([50, 103]) torch.Size([50])\n",
      "86 torch.Size([50, 103]) torch.Size([50])\n",
      "87 torch.Size([50, 103]) torch.Size([50])\n",
      "88 torch.Size([50, 103]) torch.Size([50])\n",
      "89 torch.Size([50, 103]) torch.Size([50])\n",
      "90 torch.Size([50, 103]) torch.Size([50])\n",
      "91 torch.Size([50, 103]) torch.Size([50])\n",
      "92 torch.Size([50, 103]) torch.Size([50])\n",
      "93 torch.Size([50, 103]) torch.Size([50])\n",
      "94 torch.Size([50, 103]) torch.Size([50])\n",
      "95 torch.Size([28, 103]) torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "# test the define dataset with data loader\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched[0].size(),sample_batched[1].size())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
